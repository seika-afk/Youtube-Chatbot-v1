# -*- coding: utf-8 -*-
"""YoutubeChatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WSJos90M4QqiCamENs6dZrWxkZCt4P9n
"""

import os

!pip install -q youtube-transcript-api langchain-community langchain-openai \
               faiss-cpu tiktoken python-dotenv

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate

"""# Step 1 : INdexing : Document Ingestion"""

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled

video_id = "MoN9ql6Yymw"

try:
    yt_api = YouTubeTranscriptApi()  # instantiate the class
    transcript_list = yt_api.fetch(video_id, languages=["en"])

    print(transcript_list)

except TranscriptsDisabled:
    print("No captions available for this video.")

for i in range(5):
  print("Text : ",transcript_list[i].text)
  print("Started at :",transcript_list[i].text)

chunks = [
    {"text": snippet.text, "start": snippet.start, "duration": snippet.duration}
    for snippet in transcript_list
]

chunks[:3]

transcript_list=[chunk.text for chunk in transcript_list]

transcript_list[:2]

"""# Step 1-b : INDEXING : Text Splitting"""

splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)
chunks_=splitter.create_documents(transcript_list)

len(chunks_)

"""# Step 1c and 1d : Embeddings and Storing Vector Store"""

from langchain_community.embeddings import HuggingFaceEmbeddings

embedding =HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-l6-v2")
vector_store=FAISS.from_documents(chunks_,embedding)

"""# Step 2 : Retrieval"""

retriever = vector_store.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 6, "lambda_mult": 0.5}
)

retriever.invoke("whats the song about.")

"""# Step 3 - Augmentation"""

prompt=PromptTemplate(
    template="""
  You are a helpful and knowledgeable YouTube assistant.
You are given the context of a YouTube video (such as the transcript or description).
Based on this context, your job is to accurately answer questions related to the video.
If the context is clear and sufficient, provide a direct and informative answer.
If the context is missing or unclear, simply reply:
“I’m sorry, but I don’t have enough information to answer that.”
Be concise, factual, and avoid making assumptions beyond the provided context.
      {context}
      Question: {question}
""" ,input_variables=['context','question'])

question="is this song bad"
retrieved_docs=retriever.invoke(question)

context_text = "\n\n".join(doc.page_content for doc in retrieved_docs)
context_text

final_prompt = prompt.invoke({"context": context_text, "question": question})

final_prompt

"""# Step-4  : Generation"""

from huggingface_hub import InferenceClient

client = InferenceClient(
    provider="novita",
    api_key="useYours",
)

completion = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=[
        {
            "role": "user",
            "content": str(final_prompt)
        }
    ],
)

completion.choices[0].message.content

import re

question=input(" >> ")
retrieved_docs=retriever.invoke(question)

context_text = "\n\n".join(doc.page_content for doc in retrieved_docs)
context_text

final_prompt = prompt.invoke({"context": context_text, "question": question})




completion = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-R1",
    messages=[
        {
            "role": "user",
            "content": str(final_prompt)
        }
    ],
)

text=completion.choices[0].message.content

if "</think>" in text:
    answer = text.split("</think>")[-1].strip()
    print(answer)
else:
    print("No <think> block found.")

